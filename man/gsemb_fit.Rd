% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/api.R
\name{gsemb_fit}
\alias{gsemb_fit}
\title{Fit gene and gene set embeddings from PPI and gene sets}
\usage{
gsemb_fit(
  ppi,
  gene_sets,
  node1 = "node1",
  node2 = "node2",
  weight = NULL,
  directed = FALSE,
  nodes = NULL,
  method = c("svd", "torch_autoencoder", "set2gaussian_torch"),
  dim = 64,
  k = 128,
  alpha = 0.5,
  tol = 1e-10,
  max_iter = 200,
  normalize = "col",
  epochs = 200,
  lr = 0.005,
  batch_size = 8,
  seed = 1,
  device = c("cpu", "cuda"),
  ...
)
}
\arguments{
\item{ppi}{Either a data.frame edge list or a Matrix adjacency matrix.}

\item{gene_sets}{Named list of character vectors (gene IDs).}

\item{node1, node2}{Column names in `ppi` when `ppi` is a data.frame.}

\item{weight}{Optional weight column name in `ppi` when `ppi` is a data.frame.}

\item{directed}{Logical; whether the graph is directed.}

\item{nodes}{Optional node ID vector used to restrict/order the graph.}

\item{method}{Embedding method: `"svd"`, `"torch_autoencoder"`, or `"set2gaussian_torch"`.}

\item{dim}{Embedding dimension.}

\item{k}{Number of landmarks used for diffusion features.}

\item{alpha}{Restart probability for diffusion.}

\item{tol}{Convergence tolerance for diffusion.}

\item{max_iter}{Maximum diffusion iterations.}

\item{normalize}{Normalization for `gsemb_transition_matrix`.}

\item{epochs, lr, batch_size}{Training hyperparameters for torch methods.}

\item{seed}{Random seed.}

\item{device}{`"cpu"` or `"cuda"` (falls back to CPU if CUDA is unavailable).}

\item{...}{Passed through to the selected training backend.}
}
\value{
A `gsemb_embedding` object with components:
  `gene_embedding`, `set_mu`, `set_var`, `adj`, and training metadata.
}
\description{
This is the main entry point: build a graph from a PPI edge list (or accept
a pre-built adjacency matrix), compute diffusion features, learn a gene
embedding, and derive diagonal Gaussian embeddings for gene sets. Optionally,
train a Set2Gaussian model with torch.
}
